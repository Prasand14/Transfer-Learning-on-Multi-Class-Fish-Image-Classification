{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prasa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.callbacks import EarlyStopping, History, ModelCheckpoint\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Reshape, Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = np.load('train_features.npy')\n",
    "valid_features = np.load('valid_features.npy')\n",
    "test_features = np.load(\"test_features.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = \"nw_train/\"\n",
    "valid_dir = \"nw_valid/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GETTING TRAIN DATASET LABELS\n",
    "train_labels = []\n",
    "for species in classes:\n",
    "    l = [species] * len(os.listdir(train_dir + species + '/'))\n",
    "    train_labels.extend(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GETTING VALID DATASET LABELS\n",
    "validation_labels = []\n",
    "for species in classes:\n",
    "    l = [species] * len(os.listdir(valid_dir + species + '/'))\n",
    "    validation_labels.extend(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to_categorical converts a class vector (integers) to binary class matrix.\n",
    "#for use with categorical_crossentropy.\n",
    "\n",
    "encoded_train = np_utils.to_categorical(LabelEncoder().fit_transform(train_labels))\n",
    "\n",
    "encoded_valid = np_utils.to_categorical(LabelEncoder().fit_transform(validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Custom_vgg_model_1\n",
    "#Training the classifier alone\n",
    "shape = Input(shape=(150, 150,3))\n",
    "\n",
    "model = VGG16(input_tensor=None, include_top=False,\n",
    "              weights='imagenet', input_shape = shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Adding new layers...')\n",
    "output = model.get_layer(index = -1).output  \n",
    "output = Flatten()(output)\n",
    "\n",
    "# FULLY CONNECTED LAYER\n",
    "output = Dense(4096,activation = \"relu\")(output)\n",
    "output = BatchNormalization()(output)\n",
    "output = Dropout(0.5)(output)\n",
    "output = Dense(512,activation = \"relu\")(output)\n",
    "output = BatchNormalization()(output)\n",
    "output = Dropout(0.5)(output)\n",
    "\n",
    "# LOGISTIC LAYER\n",
    "output = Dense(8, activation='softmax')(output)\n",
    "\n",
    "custom_vgg_model = Model(model.input, output)\n",
    "custom_vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in vgg16_model.layers[:19]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ImageDataGenerator - Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches) indefinitely. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_image_gen = ImageDataGenerator(\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        rotation_range=10.,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "val_image_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Autosave best Model\n",
    "callbacks = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto') \n",
    "\n",
    "#EarlyStopping - Stop training when a monitored quantity has stopped improving.\n",
    "model_file = \"./data_augmented_weights.h5\"\n",
    "\n",
    "# ModelCheckpoint - Save the model after every epoch.\n",
    "final_model = ModelCheckpoint(filepath = model_file, monitor='val_acc', verbose = 1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = vgg16_model.fit_generator(train_image_gen.flow(train_features, encoded_train, batch_size=16), nb_epoch=4,\n",
    "              samples_per_epoch = 3026,                     \n",
    "              validation_data=val_image_gen.flow(valid_features,encoded_valid,batch_size=16,shuffle=False),\n",
    "                                    nb_val_samples=750,callbacks = [callbacks,final_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SUMMARIZE ACCURACY HISTORY\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['acc']); plt.plot(history.history['val_acc']);\n",
    "plt.title('Model Accuracy'); plt.ylabel('Accuracy');\n",
    "plt.xlabel('epoch'); plt.legend(['train', 'valid'], loc='upper left');\n",
    "\n",
    "# SUMMARIZE lOSS HISTORY\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss']); plt.plot(history.history['val_loss']);\n",
    "plt.title('Model Loss'); plt.ylabel('Loss');\n",
    "plt.xlabel('epoch'); plt.legend(['train', 'valid'], loc='upper left');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(test_features, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission1 = pd.DataFrame(predictions, columns= classes)\n",
    "test_files = os.listdir(\"test_stg1/test_stg1/\")\n",
    "submission.insert(0, 'image', test_files)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clipped_predictions = np.clip(predictions,(1-0.82)/7,0.82)\n",
    "\n",
    "submission2 = pd.DataFrame(clipped_predictions, columns= classes)\n",
    "submission2.insert(0, 'image', test_files)\n",
    "submission2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission2.to_csv(\"Augmented_and_Batch_Normalised.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
